{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indiana Pines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightning import Trainer\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from src.util.torch import resolve_torch_device\n",
    "from src.util.hsi import (\n",
    "    extract_patches,\n",
    "    reduce_hsi_dim,\n",
    "    train_test_band_patch_split,\n",
    "    preprocess_hsi,\n",
    "    to_bin_labels_mask,\n",
    "    to_bin_labels,\n",
    "    to_pu_labels,\n",
    "    PreProcessType,\n",
    "    DimReductionType,\n",
    ")\n",
    "from src.data.indian_pines import load_indian_pines\n",
    "from src.model.hsic import HyperSpectralImageClassifier\n",
    "from src.model.lenet import FullyConvolutionalLeNet, PuLeNet\n",
    "from src.visualization.plot import (\n",
    "    plot_segmentation_comparison,\n",
    "    plot_numbers_distribution,\n",
    "    plot_epoch_generic_comparison,\n",
    "    plot_epoch_generic,\n",
    ")\n",
    "from src.data.dataset_decorator import UnlabeledDatasetDecorator\n",
    "from src.util.reporting import (\n",
    "    create_model_name,\n",
    "    report_run,\n",
    "    read_report_to_show,\n",
    "    lightning_metrics,\n",
    ")\n",
    "from src.util.list_ext import smooth_moving_average\n",
    "from src.util.loss import PULoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Prepare env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 100\n",
    "scheduler_step_size = num_epochs // 10\n",
    "scheduler_gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 9\n",
    "target_dim = 75\n",
    "examples_per_class = []\n",
    "smoth_window = 20\n",
    "\n",
    "pre_process_type = PreProcessType.STANDARTIZATION\n",
    "dim_reduction_type = DimReductionType.PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "device = resolve_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Device is cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Device is {device}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, labels = load_indian_pines()\n",
    "\n",
    "image_h, image_w, image_c = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, image = preprocess_hsi(image, pre_process_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, target_dim, image = reduce_hsi_dim(\n",
    "    image, target_dim, dim_reduction_type, device, random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = extract_patches(image, labels, patch_size=patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of classes 17'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(y))\n",
    "\n",
    "f\"Number of classes {num_classes}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_per_class = [20] * num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if examples_per_class:\n",
    "    x_train, y_train, x_test, y_test, y_masked = train_test_band_patch_split(\n",
    "        x, y, examples_per_class, \"indian_pines\"\n",
    "    )\n",
    "\n",
    "    plot_segmentation_comparison(\n",
    "        to_bin_labels_mask(y).reshape(image_h, image_w),\n",
    "        to_bin_labels_mask(y_masked).reshape(image_h, image_w),\n",
    "        title2=\"Masked\",\n",
    "    )\n",
    "else:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=random_seed, stratify=y\n",
    "    )\n",
    "\n",
    "y = to_bin_labels(y)\n",
    "y_train = to_bin_labels(y_train)\n",
    "y_test = to_bin_labels(y_test)\n",
    "\n",
    "x_train = np.concatenate((x_train, x_test))\n",
    "y_train = np.concatenate((y_train, np.repeat(-1, len(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.tensor(x, dtype=torch.float32).permute(0, 3, 1, 2) \n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Setting num_workers to 24'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count = multiprocessing.cpu_count()\n",
    "\n",
    "f\"Setting num_workers to {cpu_count}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "full_dataset = data.TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=cpu_count,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "test_loader = data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=cpu_count,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "full_loader = data.DataLoader(\n",
    "    full_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=cpu_count,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "predict_loader = data.DataLoader(\n",
    "    UnlabeledDatasetDecorator(full_dataset),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=cpu_count,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training samples: 21025, Testing samples: 20685'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Training samples: {len(train_dataset)}, Testing samples: {len(test_dataset)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.0918e-04, 9.4032e-01, 5.8770e-02])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "class_weights = 1.0 / counts \n",
    "class_weights = class_weights / class_weights.sum() \n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4875)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, counts = torch.unique(y_tensor, return_counts=True)\n",
    "\n",
    "positive_prob = counts[1] / counts.sum()\n",
    "\n",
    "positive_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.dbda import DBDA\n",
    "\n",
    "\n",
    "loss_fun = PULoss(prior=positive_prob)\n",
    "\n",
    "backbone = DBDA(\n",
    "    band=target_dim,\n",
    "    classes=1,\n",
    ")\n",
    "\n",
    "pred_extractor = lambda logits: (torch.sigmoid(logits) > 0.5).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/melal/Workspace/spatial-regulated-self-training/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "model = HyperSpectralImageClassifier(\n",
    "    backbone,\n",
    "    num_classes,\n",
    "    lr=learning_rate,\n",
    "    loss_fun=loss_fun,\n",
    "    # scheduler=lambda opt: StepLR(\n",
    "    #     opt, step_size=scheduler_step_size, gamma=scheduler_gamma\n",
    "    # ),\n",
    "    pred_extractor=pred_extractor,\n",
    ")\n",
    "\n",
    "trainer = Trainer(accelerator=\"auto\", devices=1, max_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melal/Workspace/spatial-regulated-self-training/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                 | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | net              | DBDA                 | 150 K  | train\n",
      "1 | loss_fun         | PULoss               | 0      | train\n",
      "2 | f1               | MulticlassF1Score    | 0      | train\n",
      "3 | overall_accuracy | MulticlassAccuracy   | 0      | train\n",
      "4 | average_accuracy | MulticlassAccuracy   | 0      | train\n",
      "5 | kappa            | MulticlassCohenKappa | 0      | train\n",
      "------------------------------------------------------------------\n",
      "150 K     Trainable params\n",
      "0         Non-trainable params\n",
      "150 K     Total params\n",
      "0.602     Total estimated model params size (MB)\n",
      "47        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c044807de93499a9ab9d4cd6cc903d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_loader,\n",
    "    # test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smothed_train = smooth_moving_average(\n",
    "#     [it.loss.cpu() for it in model.train_metrics], smoth_window\n",
    "# )\n",
    "# smothed_eval = smooth_moving_average(\n",
    "#     [it.loss.cpu() for it in model.val_metrics], smoth_window\n",
    "# )\n",
    "\n",
    "# plot_epoch_generic_comparison(smothed_train, smothed_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth_f1 = smooth_moving_average(\n",
    "#     [it.f1.cpu() for it in model.val_metrics], smoth_window\n",
    "# )\n",
    "\n",
    "# plot_epoch_generic(smooth_f1, desc=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result = trainer.validate(model, full_loader)\n",
    "\n",
    "validation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Display prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trainer.predict(model, predict_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.cat(y_pred, dim=0)\n",
    "# y_pred = pred_extractor(y_pred)\n",
    "y_pred = y_pred.reshape(image_h, image_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_segmentation_comparison(y.reshape(image_h, image_w), y_pred.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = create_model_name(\"ground_indian_pines_\", examples_per_class)\n",
    "model_category = \"lenet\"\n",
    "\n",
    "report_run(\n",
    "    model_name=model_name,\n",
    "    model_category=model_category,\n",
    "    run_desc=\"Std, more epochs, PULoss, pass whole dataset\",\n",
    "    run_params={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"patch_size\": patch_size,\n",
    "        \"target_dim\": target_dim,\n",
    "        \"scheduler_step_size\": scheduler_step_size,\n",
    "        \"scheduler_gamma\": scheduler_gamma,\n",
    "        \"pre_process_type\": str(pre_process_type),\n",
    "        \"dim_reduction_type\": str(dim_reduction_type),\n",
    "    },\n",
    "    run_metrics=lightning_metrics(validation_result),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_report_to_show(model_name, sort_by_metric=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_report_to_show(model_name, sort_by_metric=\"OA\", model_category=model_category)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
